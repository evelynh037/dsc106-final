{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a03be7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/amily/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/amily/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://github.com/evelynh037/dsc106-final/raw/main/src/data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9abe828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hillary have 3226 tweets, Trump have 3218 tweets. 18.51% of Hillary tweets are retweets, 3.88% of Trump tweets are retweets'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get df for each other\n",
    "hc = df[df[\"handle\"] == \"HillaryClinton\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "dt = df[df[\"handle\"] == \"realDonaldTrump\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "f'Hillary have {hc.shape[0]} tweets, Trump have {dt.shape[0]} tweets. {((hc[\"is_retweet\"].sum()/hc.shape[0]) * 100).round(2)}% of Hillary tweets are retweets, {((dt[\"is_retweet\"].sum()/dt.shape[0]) * 100).round(2)}% of Trump tweets are retweets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0800b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove retweet\n",
    "df = df[df[\"is_retweet\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbaffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned text\n",
    "def clean_and_tokenize(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    # Tokenize by splitting on whitespace\n",
    "    tokens = tweet.split()\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "hc[\"text_cleaned\"] = hc[\"text\"].apply(clean_and_tokenize)\n",
    "dt[\"text_cleaned\"] = dt[\"text\"].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "827a861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>703</td>\n",
       "      <td>21.791692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hillary</td>\n",
       "      <td>679</td>\n",
       "      <td>21.047737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald</td>\n",
       "      <td>414</td>\n",
       "      <td>12.833230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president</td>\n",
       "      <td>263</td>\n",
       "      <td>8.152511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trumps</td>\n",
       "      <td>197</td>\n",
       "      <td>6.106634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>renta</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>latinas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>afroamericanas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>afectadas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>luchan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Frequency    percent\n",
       "0              trump        703  21.791692\n",
       "1            hillary        679  21.047737\n",
       "2             donald        414  12.833230\n",
       "3          president        263   8.152511\n",
       "4             trumps        197   6.106634\n",
       "...              ...        ...        ...\n",
       "5981           renta          1   0.030998\n",
       "5982         latinas          1   0.030998\n",
       "5983  afroamericanas          1   0.030998\n",
       "5984       afectadas          1   0.030998\n",
       "5985          luchan          1   0.030998\n",
       "\n",
       "[5986 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_words = [token for word in hc[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "hc_counts = Counter(hc_words)\n",
    "hc_most_common_word = hc_counts.most_common(100000000000)\n",
    "hc_summary = pd.DataFrame(hc_most_common_word, columns=['Word', 'Frequency'])\n",
    "hc_summary[\"percent\"] = hc_summary[\"Frequency\"]/hc.shape[0]*100\n",
    "#hc_summary.to_csv('hillary_words.csv')\n",
    "hc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1959c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>517</td>\n",
       "      <td>16.065879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>440</td>\n",
       "      <td>13.673089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillary</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>240</td>\n",
       "      <td>7.458048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>presidentsand</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>slogan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>globalism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>americanism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>crucialonly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency    percent\n",
       "0             thank        517  16.065879\n",
       "1             great        440  13.673089\n",
       "2           hillary        326  10.130516\n",
       "3             trump        326  10.130516\n",
       "4               amp        240   7.458048\n",
       "...             ...        ...        ...\n",
       "3430  presidentsand          1   0.031075\n",
       "3431         slogan          1   0.031075\n",
       "3432      globalism          1   0.031075\n",
       "3433    americanism          1   0.031075\n",
       "5221    crucialonly          1   0.031075\n",
       "\n",
       "[5222 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_words = [token for word in dt[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "dt_counts = Counter(dt_words)\n",
    "dt_most_common_word = dt_counts.most_common(10000000000)\n",
    "dt_summary = pd.DataFrame(dt_most_common_word, columns=['Word', 'Frequency'])\n",
    "dt_summary[\"percent\"] = dt_summary[\"Frequency\"]/dt.shape[0] * 100\n",
    "dt_summary = dt_summary.sort_values(\"percent\", ascending = False)\n",
    "#dt_summary.to_csv('trump_words.csv')\n",
    "dt_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_summary.to_json('data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9030dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.153750774953503% of Hillary tweets have ！mark, 62.83405842137974% of Trump tweets have ！mark'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclamation mark\n",
    "hc_exclamation = hc[hc[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "dt_exclamation = dt[dt[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "f'{hc_exclamation / hc.shape[0] * 100}% of Hillary tweets have ！mark, {dt_exclamation / dt.shape[0]* 100}% of Trump tweets have ！mark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7eba2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.702417854928704% of Hillary tweets is quoting of her own words, 0.06215040397762585% of Trump tweets is quoting of his words'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quote of their own\n",
    "hc_quote = hc[hc[\"text\"].str.contains(\"—hillary\", case=False, na=False)].shape[0]\n",
    "dt_quote = dt[dt[\"text\"].str.contains(\"- trump\", case=False, na=False)].shape[0]\n",
    "f'{hc_quote / hc.shape[0] * 100}% of Hillary tweets is quoting of her own words, {dt_quote / dt.shape[0]* 100}% of Trump tweets is quoting of his words'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdafcda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24798512089274644% of Hillary tweets is quoting of Trump, 0.0% of Trump tweets is quoting of Hillary'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quote of each other\n",
    "hc_qo = hc[hc[\"text\"].str.contains(\"—Trump\", case=False, na=False)].shape[0]\n",
    "dt_qo = dt[dt[\"text\"].str.contains(\"-hiliary\", case=False, na=False)].shape[0]\n",
    "f'{hc_qo / hc.shape[0] * 100}% of Hillary tweets is quoting of Trump, {dt_qo / dt.shape[0]* 100}% of Trump tweets is quoting of Hillary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11eae27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8679479231246126% of Hillary tweets mentioned Stronger Together, 2.050963331261653% of Trump tweets meantioned MEGA'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##campaign slogan\n",
    "hc_slogan = hc[hc[\"text\"].str.contains(\"Stronger Together\", case=False, na=False)].shape[0]\n",
    "dt_slogan = dt[dt[\"text\"].str.contains(\"maga\",case=False, na=False)].shape[0]\n",
    "f'{hc_slogan/ hc.shape[0] * 100}% of Hillary tweets mentioned Stronger Together, {dt_slogan / dt.shape[0]* 100}% of Trump tweets meantioned MEGA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "608d439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About immigration, Trump often use ['wall', 'illegal', 'mexico', 'borders', 'border', 'refugees', 'illegals', 'wallace', 'illegally', 'refugee', 'walls', 'wallsis', 'wallet', 'interviewall', 'borderless', 'prowall', 'deportation'] and it consists of 463.02050963331254 of his tweets,Hillary often use ['wall', 'walls', 'deport', 'mexico', 'deportation', 'deported', 'illegal', 'deportar', 'stonewall', 'deportación', 'refugees', 'wallet', 'wallinstead', 'walldid', 'deporting', 'refugee', 'border', 'deportations'] and it consists of 257.2845629262244 of her tweets, one of it is about Lets imagine a tomorrow in which no child grows up under the shadows of discrimination or deportation\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trump immigration promise\n",
    "immig_words = [\"border\", \"deport\", \"mexico\", \"wall\", \"refugee\",\"illegal\"]\n",
    "dt_immig = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "dt_immig_words = [i for i in dt_immig[\"Word\"]]\n",
    "dt_immig_p = dt_immig.sum()\n",
    "hc_immig = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "hc_immig_words = [i for i in hc_immig[\"Word\"]]\n",
    "hc_immig_p = hc_immig.sum()\n",
    "f'About immigration, Trump often use {dt_immig_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_immig_words} and it consists of {hc_immig_p.loc[\"percent\"]*100} of her tweets, one of it is about Lets imagine a tomorrow in which no child grows up under the shadows of discrimination or deportation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "255c7342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About immigration, Trump often use [\\'tax\\', \\'taxes\\', \\'overtaxes\\', \\'overtaxed\\', \\'taxpayers\\'] and it consists of 463.02050963331254 of his tweets,Hillary often use [\\'tax\\', \\'taxes\\', \\'taxpayers\\', \\'taxpayer\\', \\'taxesand\\'] and it consists of 285.18288902665836 of her tweets, one of it is about Last night, Donald Trump said not paying taxes was \"smart.\" You know what I call it? Unpatriotic.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trump tax cut\n",
    "tax_words = [\"tax\"]\n",
    "dt_tax = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "dt_tax_words = [i for i in dt_tax[\"Word\"]]\n",
    "dt_tax_p = dt_tax.sum()\n",
    "hc_tax = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "hc_tax_words = [i for i in hc_tax[\"Word\"]]\n",
    "hc_tax_p = hc_tax.sum()\n",
    "f'About immigration, Trump often use {dt_tax_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_tax_words} and it consists of {hc_tax_p.loc[\"percent\"]*100} of her tweets, one of it is about Last night, Donald Trump said not paying taxes was \"smart.\" You know what I call it? Unpatriotic.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2ff001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About health plan, Trump often use ['care', 'obamacare', 'careful', 'healthcare', 'cares', 'career', 'scared', 'pledgecareful', 'ocare', 'childcare', 'careers', 'careless', 'scare'] and it consists of 463.02050963331254% of his tweets,Hillary often use ['care', 'affordable', 'career', 'cares', 'scared', 'careerfocused', 'scares', 'careerand', 'childcare', 'medicare', 'heath', 'scare'] and it consists of 291.38251704897704 of her tweets.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hillary health promise(need to be modified)\n",
    "health_words = [\"heath\",\"affordable\",\"care\"]\n",
    "dt_health = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "dt_health_words = [i for i in dt_health[\"Word\"]]\n",
    "dt_health_p = dt_health.sum()\n",
    "hc_health = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "hc_health_words = [i for i in hc_health[\"Word\"]]\n",
    "hc_health_p = hc_health.sum()\n",
    "f'About health plan, Trump often use {dt_health_words} and it consists of {dt_immig_p.loc[\"percent\"]*100}% of his tweets,Hillary often use {hc_health_words} and it consists of {hc_health_p.loc[\"percent\"]*100} of her tweets.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad5722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
