{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03be7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9abe828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get df for each other\n",
    "hc = df[df[\"handle\"] == \"HillaryClinton\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "dt = df[df[\"handle\"] == \"realDonaldTrump\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "f'Hillary have {hc.shape[0]} tweets, Trump have {dt.shape[0]} tweets. {((hc[\"is_retweet\"].sum()/hc.shape[0]) * 100).round(2)}% of Hillary tweets are retweets, {((dt[\"is_retweet\"].sum()/dt.shape[0]) * 100).round(2)}% of Trump tweets are retweets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0800b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove retweet\n",
    "df = df[df[\"is_retweet\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned text\n",
    "def clean_and_tokenize(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    # Tokenize by splitting on whitespace\n",
    "    tokens = tweet.split()\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "hc[\"text_cleaned\"] = hc[\"text\"].apply(clean_and_tokenize)\n",
    "dt[\"text_cleaned\"] = dt[\"text\"].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827a861f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_words = [token for word in hc[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "hc_counts = Counter(hc_words)\n",
    "hc_most_common_word = hc_counts.most_common(100000000000)\n",
    "hc_summary = pd.DataFrame(hc_most_common_word, columns=['Word', 'Frequency'])\n",
    "hc_summary[\"percent\"] = hc_summary[\"Frequency\"]/hc.shape[0]*100\n",
    "#hc_summary.to_csv('hillary_words.csv')\n",
    "hc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1959c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_words = [token for word in dt[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "dt_counts = Counter(dt_words)\n",
    "dt_most_common_word = dt_counts.most_common(10000000000)\n",
    "dt_summary = pd.DataFrame(dt_most_common_word, columns=['Word', 'Frequency'])\n",
    "dt_summary[\"percent\"] = dt_summary[\"Frequency\"]/dt.shape[0] * 100\n",
    "dt_summary = dt_summary.sort_values(\"percent\", ascending = False)\n",
    "#dt_summary.to_csv('trump_words.csv')\n",
    "dt_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_summary.to_json('data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9030dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclamation mark\n",
    "hc_exclamation = hc[hc[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "dt_exclamation = dt[dt[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "f'{hc_exclamation / hc.shape[0] * 100}% of Hillary tweets have ！mark, {dt_exclamation / dt.shape[0]* 100}% of Trump tweets have ！mark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba2299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quote of their own\n",
    "hc_quote = hc[hc[\"text\"].str.contains(\"—hillary\", case=False, na=False)].shape[0]\n",
    "dt_quote = dt[dt[\"text\"].str.contains(\"- trump\", case=False, na=False)].shape[0]\n",
    "f'{hc_quote / hc.shape[0] * 100}% of Hillary tweets is quoting of her own words, {dt_quote / dt.shape[0]* 100}% of Trump tweets is quoting of his words'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafcda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quote of each other\n",
    "hc_qo = hc[hc[\"text\"].str.contains(\"—Trump\", case=False, na=False)].shape[0]\n",
    "dt_qo = dt[dt[\"text\"].str.contains(\"-hiliary\", case=False, na=False)].shape[0]\n",
    "f'{hc_qo / hc.shape[0] * 100}% of Hillary tweets is quoting of Trump, {dt_qo / dt.shape[0]* 100}% of Trump tweets is quoting of Hillary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eae27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##campaign slogan\n",
    "hc_slogan = hc[hc[\"text\"].str.contains(\"Stronger Together\", case=False, na=False)].shape[0]\n",
    "dt_slogan = dt[dt[\"text\"].str.contains(\"maga\",case=False, na=False)].shape[0]\n",
    "f'{hc_slogan/ hc.shape[0] * 100}% of Hillary tweets mentioned Stronger Together, {dt_slogan / dt.shape[0]* 100}% of Trump tweets meantioned MEGA'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trump immigration promise\n",
    "immig_words = [\"border\", \"deport\", \"mexico\", \"wall\", \"refugee\",\"illegal\"]\n",
    "dt_immig = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "dt_immig_words = [i for i in dt_immig[\"Word\"]]\n",
    "dt_immig_p = dt_immig.sum()\n",
    "hc_immig = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "hc_immig_words = [i for i in hc_immig[\"Word\"]]\n",
    "hc_immig_p = hc_immig.sum()\n",
    "f'About immigration, Trump often use {dt_immig_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_immig_words} and it consists of {hc_immig_p.loc[\"percent\"]*100} of her tweets, one of it is about Lets imagine a tomorrow in which no child grows up under the shadows of discrimination or deportation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trump tax cut\n",
    "tax_words = [\"tax\"]\n",
    "dt_tax = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "dt_tax_words = [i for i in dt_tax[\"Word\"]]\n",
    "dt_tax_p = dt_tax.sum()\n",
    "hc_tax = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "hc_tax_words = [i for i in hc_tax[\"Word\"]]\n",
    "hc_tax_p = hc_tax.sum()\n",
    "f'About immigration, Trump often use {dt_tax_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_tax_words} and it consists of {hc_tax_p.loc[\"percent\"]*100} of her tweets, one of it is about Last night, Donald Trump said not paying taxes was \"smart.\" You know what I call it? Unpatriotic.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ff001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hillary health promise(need to be modified)\n",
    "health_words = [\"heath\",\"affordable\",\"care\"]\n",
    "dt_health = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "dt_health_words = [i for i in dt_health[\"Word\"]]\n",
    "dt_health_p = dt_health.sum()\n",
    "hc_health = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "hc_health_words = [i for i in hc_health[\"Word\"]]\n",
    "hc_health_p = hc_health.sum()\n",
    "f'About health plan, Trump often use {dt_health_words} and it consists of {dt_immig_p.loc[\"percent\"]*100}% of his tweets,Hillary often use {hc_health_words} and it consists of {hc_health_p.loc[\"percent\"]*100} of her tweets.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad5722",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
