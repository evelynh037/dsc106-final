{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a03be7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/fejiang/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/fejiang/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://github.com/evelynh037/dsc106-final/raw/main/src/data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726403f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://github.com/evelynh037/dsc106-final/raw/main/src/data/tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ba026c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97b9ec73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>handle</th>\n",
       "      <th>text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>original_author</th>\n",
       "      <th>time</th>\n",
       "      <th>in_reply_to_screen_name</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>...</th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_country_code</th>\n",
       "      <th>place_country</th>\n",
       "      <th>place_contained_within</th>\n",
       "      <th>place_attributes</th>\n",
       "      <th>place_bounding_box</th>\n",
       "      <th>source_url</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>extended_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>780925634159796224</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>The question in this election: Who can put the...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-28T00:22:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.twitter.com</td>\n",
       "      <td>False</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/Xr...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/Xr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780916180899037184</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>Last night, Donald Trump said not paying taxes...</td>\n",
       "      <td>True</td>\n",
       "      <td>timkaine</td>\n",
       "      <td>2016-09-27T23:45:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com</td>\n",
       "      <td>False</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/t0...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/t0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>780911564857761793</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>Couldn't be more proud of @HillaryClinton. Her...</td>\n",
       "      <td>True</td>\n",
       "      <td>POTUS</td>\n",
       "      <td>2016-09-27T23:26:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://about.twitter.com/products/tweetdeck</td>\n",
       "      <td>False</td>\n",
       "      <td>{'user_mentions': [{'id_str': '1536791610', 'n...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>780907038650068994</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>If we stand together, there's nothing we can't...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-27T23:08:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://studio.twitter.com</td>\n",
       "      <td>False</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/Q3...</td>\n",
       "      <td>{'media': [{'display_url': 'pic.twitter.com/Q3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>780897419462602752</td>\n",
       "      <td>HillaryClinton</td>\n",
       "      <td>Both candidates were asked about how they'd co...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-09-27T22:30:27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://about.twitter.com/products/tweetdeck</td>\n",
       "      <td>False</td>\n",
       "      <td>{'user_mentions': [], 'symbols': [], 'urls': [...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id          handle  \\\n",
       "0  780925634159796224  HillaryClinton   \n",
       "1  780916180899037184  HillaryClinton   \n",
       "2  780911564857761793  HillaryClinton   \n",
       "3  780907038650068994  HillaryClinton   \n",
       "4  780897419462602752  HillaryClinton   \n",
       "\n",
       "                                                text  is_retweet  \\\n",
       "0  The question in this election: Who can put the...       False   \n",
       "1  Last night, Donald Trump said not paying taxes...        True   \n",
       "2  Couldn't be more proud of @HillaryClinton. Her...        True   \n",
       "3  If we stand together, there's nothing we can't...       False   \n",
       "4  Both candidates were asked about how they'd co...       False   \n",
       "\n",
       "  original_author                 time in_reply_to_screen_name  \\\n",
       "0             NaN  2016-09-28T00:22:34                     NaN   \n",
       "1        timkaine  2016-09-27T23:45:00                     NaN   \n",
       "2           POTUS  2016-09-27T23:26:40                     NaN   \n",
       "3             NaN  2016-09-27T23:08:41                     NaN   \n",
       "4             NaN  2016-09-27T22:30:27                     NaN   \n",
       "\n",
       "   in_reply_to_status_id  in_reply_to_user_id  is_quote_status  ...  \\\n",
       "0                    NaN                  NaN            False  ...   \n",
       "1                    NaN                  NaN            False  ...   \n",
       "2                    NaN                  NaN            False  ...   \n",
       "3                    NaN                  NaN            False  ...   \n",
       "4                    NaN                  NaN            False  ...   \n",
       "\n",
       "  place_type  place_country_code  place_country  place_contained_within  \\\n",
       "0        NaN                 NaN            NaN                     NaN   \n",
       "1        NaN                 NaN            NaN                     NaN   \n",
       "2        NaN                 NaN            NaN                     NaN   \n",
       "3        NaN                 NaN            NaN                     NaN   \n",
       "4        NaN                 NaN            NaN                     NaN   \n",
       "\n",
       "   place_attributes place_bounding_box  \\\n",
       "0               NaN                NaN   \n",
       "1               NaN                NaN   \n",
       "2               NaN                NaN   \n",
       "3               NaN                NaN   \n",
       "4               NaN                NaN   \n",
       "\n",
       "                                     source_url truncated  \\\n",
       "0                    https://studio.twitter.com     False   \n",
       "1                            http://twitter.com     False   \n",
       "2  https://about.twitter.com/products/tweetdeck     False   \n",
       "3                    https://studio.twitter.com     False   \n",
       "4  https://about.twitter.com/products/tweetdeck     False   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'media': [{'display_url': 'pic.twitter.com/Xr...   \n",
       "1  {'media': [{'display_url': 'pic.twitter.com/t0...   \n",
       "2  {'user_mentions': [{'id_str': '1536791610', 'n...   \n",
       "3  {'media': [{'display_url': 'pic.twitter.com/Q3...   \n",
       "4  {'user_mentions': [], 'symbols': [], 'urls': [...   \n",
       "\n",
       "                                   extended_entities  \n",
       "0  {'media': [{'display_url': 'pic.twitter.com/Xr...  \n",
       "1  {'media': [{'display_url': 'pic.twitter.com/t0...  \n",
       "2                                                NaN  \n",
       "3  {'media': [{'display_url': 'pic.twitter.com/Q3...  \n",
       "4                                                NaN  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1a2c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['handle', 'text']].to_csv(\"tweets.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9abe828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hillary have 3226 tweets, Trump have 3218 tweets. 18.51% of Hillary tweets are retweets, 3.88% of Trump tweets are retweets'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get df for each other\n",
    "hc = df[df[\"handle\"] == \"HillaryClinton\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "dt = df[df[\"handle\"] == \"realDonaldTrump\"][[\"text\",\"is_retweet\",\"time\"]]\n",
    "f'Hillary have {hc.shape[0]} tweets, Trump have {dt.shape[0]} tweets. {((hc[\"is_retweet\"].sum()/hc.shape[0]) * 100).round(2)}% of Hillary tweets are retweets, {((dt[\"is_retweet\"].sum()/dt.shape[0]) * 100).round(2)}% of Trump tweets are retweets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0800b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove retweet\n",
    "df = df[df[\"is_retweet\"] == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbaffc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned text\n",
    "def clean_and_tokenize(tweet):\n",
    "    # Remove URLs\n",
    "    tweet = re.sub(r'http\\S+', '', tweet)\n",
    "    # Remove usernames\n",
    "    tweet = re.sub(r'@\\w+', '', tweet)\n",
    "    # Remove hashtags\n",
    "    tweet = re.sub(r'#\\w+', '', tweet)\n",
    "    # Remove punctuation\n",
    "    tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
    "    # Tokenize by splitting on whitespace\n",
    "    tokens = tweet.split()\n",
    "    # Convert to lowercase\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "hc[\"text_cleaned\"] = hc[\"text\"].apply(clean_and_tokenize)\n",
    "dt[\"text_cleaned\"] = dt[\"text\"].apply(clean_and_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827a861f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>trump</td>\n",
       "      <td>703</td>\n",
       "      <td>21.791692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hillary</td>\n",
       "      <td>679</td>\n",
       "      <td>21.047737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>donald</td>\n",
       "      <td>414</td>\n",
       "      <td>12.833230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>president</td>\n",
       "      <td>263</td>\n",
       "      <td>8.152511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trumps</td>\n",
       "      <td>197</td>\n",
       "      <td>6.106634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5981</th>\n",
       "      <td>afroamericanas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5982</th>\n",
       "      <td>afectadas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>luchan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5984</th>\n",
       "      <td>renta</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5985</th>\n",
       "      <td>latinas</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5986 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  Frequency    percent\n",
       "0              trump        703  21.791692\n",
       "1            hillary        679  21.047737\n",
       "2             donald        414  12.833230\n",
       "3          president        263   8.152511\n",
       "4             trumps        197   6.106634\n",
       "...              ...        ...        ...\n",
       "5981  afroamericanas          1   0.030998\n",
       "5982       afectadas          1   0.030998\n",
       "5983          luchan          1   0.030998\n",
       "5984           renta          1   0.030998\n",
       "5985         latinas          1   0.030998\n",
       "\n",
       "[5986 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_words = [token for word in hc[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "hc_counts = Counter(hc_words)\n",
    "hc_most_common_word = hc_counts.most_common(100000000000)\n",
    "hc_summary = pd.DataFrame(hc_most_common_word, columns=['Word', 'Frequency'])\n",
    "hc_summary[\"percent\"] = hc_summary[\"Frequency\"]/hc.shape[0]*100\n",
    "hc_summary.to_csv('hillary_words.csv', index = False)\n",
    "hc_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1959c556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>517</td>\n",
       "      <td>16.065879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>440</td>\n",
       "      <td>13.673089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillary</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>240</td>\n",
       "      <td>7.458048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3430</th>\n",
       "      <td>presidentsand</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>slogan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3432</th>\n",
       "      <td>americanism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3433</th>\n",
       "      <td>globalism</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5221</th>\n",
       "      <td>crucialonly</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5222 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency    percent\n",
       "0             thank        517  16.065879\n",
       "1             great        440  13.673089\n",
       "2           hillary        326  10.130516\n",
       "3             trump        326  10.130516\n",
       "4               amp        240   7.458048\n",
       "...             ...        ...        ...\n",
       "3430  presidentsand          1   0.031075\n",
       "3431         slogan          1   0.031075\n",
       "3432    americanism          1   0.031075\n",
       "3433      globalism          1   0.031075\n",
       "5221    crucialonly          1   0.031075\n",
       "\n",
       "[5222 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_words = [token for word in dt[\"text_cleaned\"] for token in set(word) if token not in stop_words]\n",
    "dt_counts = Counter(dt_words)\n",
    "dt_most_common_word = dt_counts.most_common(10000000000)\n",
    "dt_summary = pd.DataFrame(dt_most_common_word, columns=['Word', 'Frequency'])\n",
    "dt_summary[\"percent\"] = dt_summary[\"Frequency\"]/dt.shape[0] * 100\n",
    "dt_summary = dt_summary.sort_values(\"percent\", ascending = False)\n",
    "dt_summary.to_csv('trump_words.csv', index = False)\n",
    "dt_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_summary.to_json('data.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e9030dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.153750774953503% of Hillary tweets have ！mark, 62.83405842137974% of Trump tweets have ！mark'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclamation mark\n",
    "hc_exclamation = hc[hc[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "dt_exclamation = dt[dt[\"text\"].str.contains(\"!\", case=False, na=False)].shape[0]\n",
    "f'{hc_exclamation / hc.shape[0] * 100}% of Hillary tweets have ！mark, {dt_exclamation / dt.shape[0]* 100}% of Trump tweets have ！mark'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3620c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency_dt</th>\n",
       "      <th>percent_dt</th>\n",
       "      <th>Frequency_hc</th>\n",
       "      <th>percent_hc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>514</td>\n",
       "      <td>16.618170</td>\n",
       "      <td>41</td>\n",
       "      <td>1.559528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>434</td>\n",
       "      <td>14.031684</td>\n",
       "      <td>53</td>\n",
       "      <td>2.015976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillary</td>\n",
       "      <td>320</td>\n",
       "      <td>10.345942</td>\n",
       "      <td>597</td>\n",
       "      <td>22.708254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump</td>\n",
       "      <td>297</td>\n",
       "      <td>9.602328</td>\n",
       "      <td>583</td>\n",
       "      <td>22.175732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>231</td>\n",
       "      <td>7.468477</td>\n",
       "      <td>35</td>\n",
       "      <td>1.331305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2178</th>\n",
       "      <td>resources</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>pledged</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2180</th>\n",
       "      <td>kept</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>disqualifying</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>2</td>\n",
       "      <td>0.076075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>conduct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>3</td>\n",
       "      <td>0.114112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2183 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency_dt  percent_dt  Frequency_hc  percent_hc\n",
       "0             thank           514   16.618170            41    1.559528\n",
       "1             great           434   14.031684            53    2.015976\n",
       "2           hillary           320   10.345942           597   22.708254\n",
       "3             trump           297    9.602328           583   22.175732\n",
       "4               amp           231    7.468477            35    1.331305\n",
       "...             ...           ...         ...           ...         ...\n",
       "2178      resources             1    0.032331             2    0.076075\n",
       "2179        pledged             1    0.032331             2    0.076075\n",
       "2180           kept             1    0.032331             1    0.038037\n",
       "2181  disqualifying             1    0.032331             2    0.076075\n",
       "2182        conduct             1    0.032331             3    0.114112\n",
       "\n",
       "[2183 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_common=dt_summary.merge(hc_summary, left_on='Word', right_on='Word',suffixes=('_dt', '_hc'))\n",
    "words_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b43ca779",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_common = pd.read_csv('common.csv')\n",
    "words_common['category'] = words_common['category'].replace('economy', 'econ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88058d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting us\n",
      "  Downloading us-3.1.1.tar.gz (14 kB)\n",
      "Collecting jellyfish==0.11.2\n",
      "  Downloading jellyfish-0.11.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 24.0 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: us\n",
      "  Building wheel for us (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for us: filename=us-3.1.1-py3-none-any.whl size=12537 sha256=aa10cf2d08d93fc272592bbb61a7b613c672101f457e08c82103574cb174086f\n",
      "  Stored in directory: /home/fejiang/.cache/pip/wheels/29/9e/92/3672525fc19ac574d668402d739c8e8ff4650012304d2f3f06\n",
      "Successfully built us\n",
      "Installing collected packages: jellyfish, us\n",
      "\u001b[33m  WARNING: The script states is installed in '/home/fejiang/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed jellyfish-0.11.2 us-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "312a0374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import us\n",
    "# Get a list of all state names\n",
    "state_names = [state.name.lower() for state in us.states.STATES]\n",
    "\n",
    "# Get a list of state abbreviations\n",
    "state_abbre = [state.abbr.lower() for state in us.states.STATES]\n",
    "select_state = lambda x: 'state' if x['Word'] in state_names or x['Word'] in state_abbre else x['category']\n",
    "words_common['category'] = words_common.apply(select_state, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f766a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_common['category'] = words_common['category'].replace('military', 'millitary')\n",
    "words_common['category'] = words_common['category'].fillna('other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e9f6b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "other        1613\n",
       "name           98\n",
       "neg            69\n",
       "endorse        51\n",
       "promise        50\n",
       "event          49\n",
       "security       44\n",
       "state          44\n",
       "foreign        41\n",
       "econ           37\n",
       "policy         37\n",
       "justice        29\n",
       "poverty        25\n",
       "job            24\n",
       "health         21\n",
       "patriotic      21\n",
       "union          20\n",
       "gender         18\n",
       "media          17\n",
       "race           15\n",
       "edu            14\n",
       "trade          13\n",
       "millitary      12\n",
       "slogan         11\n",
       "time           11\n",
       "immig          10\n",
       "environ         9\n",
       "tax             4\n",
       "age             4\n",
       "lgbt            4\n",
       "attack          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_common.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc1b0ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# into large categories:\n",
    "demographic = ['gender', 'race', 'age', 'lgbt']\n",
    "campaign_msg = ['slogan', 'policy', 'promise', 'event']\n",
    "national_identity = ['patriotic', 'union', 'state']\n",
    "economic_policy = ['econ', 'tax', 'job', 'trade']\n",
    "security_policy = ['foreign', 'millitary', 'security', 'immig']\n",
    "opponents_ref = ['name']\n",
    "social_issue = ['justice', 'health', 'media', 'environ', 'poverty', 'edu']\n",
    "emotional_word = ['endorse', 'neg', 'attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "536f803c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_larger_cate(x):\n",
    "    if x == 'other' or x == 'time':\n",
    "        return 'other_topic'\n",
    "    elif x in demographic:\n",
    "        return 'demographic_issue'\n",
    "    elif x in campaign_msg:\n",
    "        return 'campaign_message'\n",
    "    elif x in national_identity:\n",
    "        return 'national_identity'\n",
    "    elif x in economic_policy:\n",
    "        return 'economic_policy'\n",
    "    elif x in security_policy:\n",
    "        return 'security_policy'\n",
    "    elif x in social_issue:\n",
    "        return 'social_issue'\n",
    "    elif x in emotional_word:\n",
    "        return 'emotional_word'\n",
    "    else:\n",
    "        return 'opponents_reference'\n",
    "\n",
    "words_common['topic'] = words_common['category'].apply(add_larger_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea60c335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding sub-categories and topics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "myohe = OneHotEncoder()\n",
    "myoheclass = myohe.fit_transform(words_common.category.values.reshape(-1,1)).toarray()\n",
    "df_encoded = pd.concat([words_common, pd.DataFrame(myoheclass, columns=list(myohe.categories_[0]))], axis=1)\n",
    "\n",
    "myohe2 = OneHotEncoder()\n",
    "myohetopic = myohe2.fit_transform(words_common.topic.values.reshape(-1,1)).toarray()\n",
    "all_common = pd.concat([df_encoded, pd.DataFrame(myohetopic, columns=list(myohe2.categories_[0]))], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a28b4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_common = all_common.drop(columns = ['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed2d1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_common['total_freq'] = all_common['Frequency_dt'] + all_common['Frequency_hc']\n",
    "all_common['diff_freq'] = np.abs(all_common['Frequency_dt'] - all_common['Frequency_hc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dc58a8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency_dt</th>\n",
       "      <th>percent_dt</th>\n",
       "      <th>Frequency_hc</th>\n",
       "      <th>percent_hc</th>\n",
       "      <th>category</th>\n",
       "      <th>topic</th>\n",
       "      <th>age</th>\n",
       "      <th>attack</th>\n",
       "      <th>econ</th>\n",
       "      <th>...</th>\n",
       "      <th>demographic_issue</th>\n",
       "      <th>economic_policy</th>\n",
       "      <th>emotional_word</th>\n",
       "      <th>national_identity</th>\n",
       "      <th>opponents_reference</th>\n",
       "      <th>other_topic</th>\n",
       "      <th>security_policy</th>\n",
       "      <th>social_issue</th>\n",
       "      <th>total_freq</th>\n",
       "      <th>diff_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thank</td>\n",
       "      <td>517</td>\n",
       "      <td>16.065879</td>\n",
       "      <td>47</td>\n",
       "      <td>1.456913</td>\n",
       "      <td>event</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>564</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great</td>\n",
       "      <td>440</td>\n",
       "      <td>13.673089</td>\n",
       "      <td>63</td>\n",
       "      <td>1.952883</td>\n",
       "      <td>promise</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>503</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hillary</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "      <td>679</td>\n",
       "      <td>21.047737</td>\n",
       "      <td>name</td>\n",
       "      <td>opponents_reference</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1005</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trump</td>\n",
       "      <td>326</td>\n",
       "      <td>10.130516</td>\n",
       "      <td>703</td>\n",
       "      <td>21.791692</td>\n",
       "      <td>name</td>\n",
       "      <td>opponents_reference</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1029</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amp</td>\n",
       "      <td>240</td>\n",
       "      <td>7.458048</td>\n",
       "      <td>77</td>\n",
       "      <td>2.386857</td>\n",
       "      <td>other</td>\n",
       "      <td>other_topic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>kept</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>other</td>\n",
       "      <td>other_topic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>threatens</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>security</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2413</th>\n",
       "      <td>disqualifying</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>2</td>\n",
       "      <td>0.061996</td>\n",
       "      <td>neg</td>\n",
       "      <td>emotional_word</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>conduct</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>5</td>\n",
       "      <td>0.154991</td>\n",
       "      <td>other</td>\n",
       "      <td>other_topic</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2415</th>\n",
       "      <td>slogan</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031075</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>slogan</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2416 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Word  Frequency_dt  percent_dt  Frequency_hc  percent_hc  \\\n",
       "0             thank           517   16.065879            47    1.456913   \n",
       "1             great           440   13.673089            63    1.952883   \n",
       "2           hillary           326   10.130516           679   21.047737   \n",
       "3             trump           326   10.130516           703   21.791692   \n",
       "4               amp           240    7.458048            77    2.386857   \n",
       "...             ...           ...         ...           ...         ...   \n",
       "2411           kept             1    0.031075             1    0.030998   \n",
       "2412      threatens             1    0.031075             1    0.030998   \n",
       "2413  disqualifying             1    0.031075             2    0.061996   \n",
       "2414        conduct             1    0.031075             5    0.154991   \n",
       "2415         slogan             1    0.031075             1    0.030998   \n",
       "\n",
       "      category                topic  age  attack  econ  ...  \\\n",
       "0        event     campaign_message  0.0     0.0   0.0  ...   \n",
       "1      promise     campaign_message  0.0     0.0   0.0  ...   \n",
       "2         name  opponents_reference  0.0     0.0   0.0  ...   \n",
       "3         name  opponents_reference  0.0     0.0   0.0  ...   \n",
       "4        other          other_topic  0.0     0.0   0.0  ...   \n",
       "...        ...                  ...  ...     ...   ...  ...   \n",
       "2411     other          other_topic  0.0     0.0   0.0  ...   \n",
       "2412  security      security_policy  0.0     0.0   0.0  ...   \n",
       "2413       neg       emotional_word  0.0     0.0   0.0  ...   \n",
       "2414     other          other_topic  0.0     0.0   0.0  ...   \n",
       "2415    slogan     campaign_message  0.0     0.0   0.0  ...   \n",
       "\n",
       "      demographic_issue  economic_policy  emotional_word  national_identity  \\\n",
       "0                   0.0              0.0             0.0                0.0   \n",
       "1                   0.0              0.0             0.0                0.0   \n",
       "2                   0.0              0.0             0.0                0.0   \n",
       "3                   0.0              0.0             0.0                0.0   \n",
       "4                   0.0              0.0             0.0                0.0   \n",
       "...                 ...              ...             ...                ...   \n",
       "2411                0.0              0.0             0.0                0.0   \n",
       "2412                0.0              0.0             0.0                0.0   \n",
       "2413                0.0              0.0             1.0                0.0   \n",
       "2414                0.0              0.0             0.0                0.0   \n",
       "2415                0.0              0.0             0.0                0.0   \n",
       "\n",
       "      opponents_reference  other_topic  security_policy  social_issue  \\\n",
       "0                     0.0          0.0              0.0           0.0   \n",
       "1                     0.0          0.0              0.0           0.0   \n",
       "2                     1.0          0.0              0.0           0.0   \n",
       "3                     1.0          0.0              0.0           0.0   \n",
       "4                     0.0          1.0              0.0           0.0   \n",
       "...                   ...          ...              ...           ...   \n",
       "2411                  0.0          1.0              0.0           0.0   \n",
       "2412                  0.0          0.0              1.0           0.0   \n",
       "2413                  0.0          0.0              0.0           0.0   \n",
       "2414                  0.0          1.0              0.0           0.0   \n",
       "2415                  0.0          0.0              0.0           0.0   \n",
       "\n",
       "      total_freq  diff_freq  \n",
       "0            564        470  \n",
       "1            503        377  \n",
       "2           1005        353  \n",
       "3           1029        377  \n",
       "4            317        163  \n",
       "...          ...        ...  \n",
       "2411           2          0  \n",
       "2412           2          0  \n",
       "2413           3          1  \n",
       "2414           6          4  \n",
       "2415           2          0  \n",
       "\n",
       "[2416 rows x 49 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4c6fcf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_common.to_csv('words_in_common.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cc68a6",
   "metadata": {},
   "source": [
    "---\n",
    "Above is all stats on Words used in both candidates' tweets\n",
    "Now move on to slogans in their tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7776e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from this: https://en.wikipedia.org/wiki/List_of_U.S._presidential_campaign_slogans#:~:text=%22Ready%20for%20change%2C%20ready%20to,experience%20to%20make%20change%20happen.%22\n",
    "hc_slogan = ['hillary for america', 'stronger together', 'forward together', \"i'm with her\", 'fighting for us', 'stick it to the man by voting for a woman', 'love trumps hate', 'when they go low, we go high']\n",
    "dt_slogan = ['make america great again', 'maga', 'america first', 'promises made, promises kept']\n",
    "hc_used = []\n",
    "dt_used = []\n",
    "def check_hc_slogan(tweet):\n",
    "    match = [slogan for slogan in hc_slogan if slogan in tweet.lower()]\n",
    "    if len(match)!=0:\n",
    "        for slog in match:\n",
    "            if slog not in hc_used:\n",
    "                hc_used.append(slog)\n",
    "    return match if len(match)!= 0 else 0\n",
    "\n",
    "def check_dt_slogan(tweet):\n",
    "    match = [slogan for slogan in dt_slogan if slogan in tweet.lower()]\n",
    "    if len(match)!=0:\n",
    "        for slog in match:\n",
    "            if slog not in dt_used:\n",
    "                dt_used.append(slog)\n",
    "    return match if len(match)!= 0 else 0\n",
    "\n",
    "# Apply the function to create a new column 'included_slogans'\n",
    "hc['slogans'] = hc['text'].apply(check_hc_slogan)\n",
    "dt['slogans'] = dt['text'].apply(check_dt_slogan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d64b0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_slogan_sum = hc[hc['slogans']!=0]\n",
    "dt_slogan_sum = dt[dt['slogans']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e955e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_212/1894537887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hc_slogan_sum[slog] = hc_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hc_slogan_sum[slog] = hc_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hc_slogan_sum[slog] = hc_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  hc_slogan_sum[slog] = hc_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_slogan_sum[slog] = dt_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_slogan_sum[slog] = dt_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
      "/tmp/ipykernel_212/1894537887.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dt_slogan_sum[slog] = dt_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n"
     ]
    }
   ],
   "source": [
    "# one-hot-encode slogan\n",
    "for slog in hc_used:\n",
    "    hc_slogan_sum[slog] = hc_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))\n",
    "\n",
    "for slog in dt_used:\n",
    "    dt_slogan_sum[slog] = dt_slogan_sum['slogans'].apply(lambda slogan: int(slog in slogan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d4af17ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump's slogan stats:\n",
      "Total 168 posts contains some type of slogan\n",
      "MAGA: 66; Make America Great Again: 97;\n",
      "America First: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"Trump's slogan stats:\")\n",
    "print(f\"Total {dt_slogan_sum.shape[0]} posts contains some type of slogan\")\n",
    "print(f\"MAGA: {dt_slogan_sum.maga.sum()}; Make America Great Again: {dt_slogan_sum['make america great again'].sum()};\")\n",
    "print(f\"America First: {dt_slogan_sum['america first'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b26e2086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinton's slogan stats:\n",
      "Total 39 posts contains some type of slogan\n",
      "love trumps hate: 9; Stronger Together: 28\n",
      "Hillary for America: 1; I'm with her:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Clinton's slogan stats:\")\n",
    "print(f\"Total {hc_slogan_sum.shape[0]} posts contains some type of slogan\")\n",
    "print(f\"love trumps hate: {hc_slogan_sum['love trumps hate'].sum()}; Stronger Together: {hc_slogan_sum['stronger together'].sum()}\")\n",
    "print(f\"Hillary for America: {hc_slogan_sum['hillary for america'].sum()}; I'm with her: \", hc_slogan_sum[\"i'm with her\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e2d32e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogan</th>\n",
       "      <th>num_tweets</th>\n",
       "      <th>Clinton</th>\n",
       "      <th>Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGA</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Make America Great Again</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>America First</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love Trumps Hate</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stronger Together</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hillary for America</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I'm with her</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     slogan  num_tweets  Clinton  Trump\n",
       "0                      MAGA          66        0      1\n",
       "1  Make America Great Again          97        0      1\n",
       "2             America First           7        0      1\n",
       "3          Love Trumps Hate           9        1      0\n",
       "4         Stronger Together          28        1      0\n",
       "5       Hillary for America           1        1      0\n",
       "6              I'm with her           1        1      0"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slogan_stats = pd.DataFrame({\"slogan\": ['MAGA', 'Make America Great Again', 'America First', 'Love Trumps Hate', 'Stronger Together', 'Hillary for America', \"I'm with her\"],\n",
    "                            \"num_tweets\": [66, 97, 7, 9, 28, 1, 1], 'Clinton':[0,0,0,1,1,1,1], \"Trump\":[1,1,1,0,0,0,0]})\n",
    "slogan_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3f39a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "slogan_stats.to_csv(\"slogan_stats.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "212972ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>time</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>slogans</th>\n",
       "      <th>love trumps hate</th>\n",
       "      <th>stronger together</th>\n",
       "      <th>hillary for america</th>\n",
       "      <th>i'm with her</th>\n",
       "      <th>maga</th>\n",
       "      <th>make america great again</th>\n",
       "      <th>america first</th>\n",
       "      <th>Cliton</th>\n",
       "      <th>Trump</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>We believe that everyone has value.\\nWe believ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-09-21T19:12:46</td>\n",
       "      <td>[we, believe, that, everyone, has, value, we, ...</td>\n",
       "      <td>[love trumps hate]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Let’s make clear that love trumps hate—not jus...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-09-19T19:03:31</td>\n",
       "      <td>[lets, make, clear, that, love, trumps, hateno...</td>\n",
       "      <td>[love trumps hate]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>\"We deserve a president…who believes that each...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-09-16T19:27:44</td>\n",
       "      <td>[we, deserve, a, presidentwho, believes, that,...</td>\n",
       "      <td>[stronger together]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Let’s build a future where love trumps hate. h...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-09-16T14:05:45</td>\n",
       "      <td>[lets, build, a, future, where, love, trumps, ...</td>\n",
       "      <td>[love trumps hate]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>“She knows that love trumps hate.” —@POTUS on ...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-09-13T18:12:17</td>\n",
       "      <td>[she, knows, that, love, trumps, hate, on, hil...</td>\n",
       "      <td>[love trumps hate]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>\"@hofmannken: DonaldTrump, wish I could attend...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-01-08T03:12:06</td>\n",
       "      <td>[donaldtrump, wish, i, could, attend, one, of,...</td>\n",
       "      <td>[make america great again]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>We could only get a small fraction of this 25k...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-01-08T02:23:07</td>\n",
       "      <td>[we, could, only, get, a, small, fraction, of,...</td>\n",
       "      <td>[make america great again]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>I will be in beautiful Burlington, Vermont, to...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-01-07T13:17:40</td>\n",
       "      <td>[i, will, be, in, beautiful, burlington, vermo...</td>\n",
       "      <td>[make america great again]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6440</th>\n",
       "      <td>\"@marybnall01: @realDonaldTrump watched lowell...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-01-05T03:44:17</td>\n",
       "      <td>[watched, lowell, mass, speech, awesome, great...</td>\n",
       "      <td>[make america great again]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6443</th>\n",
       "      <td>\"@SalRiccobono: @realDonaldTrump @troyconway D...</td>\n",
       "      <td>False</td>\n",
       "      <td>2016-01-05T03:36:53</td>\n",
       "      <td>[donald, get, big, business, back, and, make, ...</td>\n",
       "      <td>[make america great again]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_retweet  \\\n",
       "265   We believe that everyone has value.\\nWe believ...       False   \n",
       "326   Let’s make clear that love trumps hate—not jus...       False   \n",
       "424   \"We deserve a president…who believes that each...       False   \n",
       "450   Let’s build a future where love trumps hate. h...       False   \n",
       "607   “She knows that love trumps hate.” —@POTUS on ...       False   \n",
       "...                                                 ...         ...   \n",
       "6400  \"@hofmannken: DonaldTrump, wish I could attend...       False   \n",
       "6402  We could only get a small fraction of this 25k...       False   \n",
       "6413  I will be in beautiful Burlington, Vermont, to...       False   \n",
       "6440  \"@marybnall01: @realDonaldTrump watched lowell...       False   \n",
       "6443  \"@SalRiccobono: @realDonaldTrump @troyconway D...       False   \n",
       "\n",
       "                     time                                       text_cleaned  \\\n",
       "265   2016-09-21T19:12:46  [we, believe, that, everyone, has, value, we, ...   \n",
       "326   2016-09-19T19:03:31  [lets, make, clear, that, love, trumps, hateno...   \n",
       "424   2016-09-16T19:27:44  [we, deserve, a, presidentwho, believes, that,...   \n",
       "450   2016-09-16T14:05:45  [lets, build, a, future, where, love, trumps, ...   \n",
       "607   2016-09-13T18:12:17  [she, knows, that, love, trumps, hate, on, hil...   \n",
       "...                   ...                                                ...   \n",
       "6400  2016-01-08T03:12:06  [donaldtrump, wish, i, could, attend, one, of,...   \n",
       "6402  2016-01-08T02:23:07  [we, could, only, get, a, small, fraction, of,...   \n",
       "6413  2016-01-07T13:17:40  [i, will, be, in, beautiful, burlington, vermo...   \n",
       "6440  2016-01-05T03:44:17  [watched, lowell, mass, speech, awesome, great...   \n",
       "6443  2016-01-05T03:36:53  [donald, get, big, business, back, and, make, ...   \n",
       "\n",
       "                         slogans  love trumps hate  stronger together  \\\n",
       "265           [love trumps hate]               1.0                0.0   \n",
       "326           [love trumps hate]               1.0                0.0   \n",
       "424          [stronger together]               0.0                1.0   \n",
       "450           [love trumps hate]               1.0                0.0   \n",
       "607           [love trumps hate]               1.0                0.0   \n",
       "...                          ...               ...                ...   \n",
       "6400  [make america great again]               0.0                0.0   \n",
       "6402  [make america great again]               0.0                0.0   \n",
       "6413  [make america great again]               0.0                0.0   \n",
       "6440  [make america great again]               0.0                0.0   \n",
       "6443  [make america great again]               0.0                0.0   \n",
       "\n",
       "      hillary for america  i'm with her  maga  make america great again  \\\n",
       "265                   0.0           0.0   0.0                       0.0   \n",
       "326                   0.0           0.0   0.0                       0.0   \n",
       "424                   0.0           0.0   0.0                       0.0   \n",
       "450                   0.0           0.0   0.0                       0.0   \n",
       "607                   0.0           0.0   0.0                       0.0   \n",
       "...                   ...           ...   ...                       ...   \n",
       "6400                  0.0           0.0   0.0                       1.0   \n",
       "6402                  0.0           0.0   0.0                       1.0   \n",
       "6413                  0.0           0.0   0.0                       1.0   \n",
       "6440                  0.0           0.0   0.0                       1.0   \n",
       "6443                  0.0           0.0   0.0                       1.0   \n",
       "\n",
       "      america first  Cliton  Trump  \n",
       "265             0.0       1      0  \n",
       "326             0.0       1      0  \n",
       "424             0.0       1      0  \n",
       "450             0.0       1      0  \n",
       "607             0.0       1      0  \n",
       "...             ...     ...    ...  \n",
       "6400            0.0       0      1  \n",
       "6402            0.0       0      1  \n",
       "6413            0.0       0      1  \n",
       "6440            0.0       0      1  \n",
       "6443            0.0       0      1  \n",
       "\n",
       "[207 rows x 14 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_slogans = pd.concat([hc_slogan_sum, dt_slogan_sum]).fillna(0)\n",
    "all_slogans['Cliton'] = np.array([1]*hc_slogan_sum.shape[0] + [0]*dt_slogan_sum.shape[0])\n",
    "all_slogans['Trump'] = np.array([0]*hc_slogan_sum.shape[0] + [1]*dt_slogan_sum.shape[0])\n",
    "all_slogans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1576ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_slogans.to_csv('all_slogans.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30844104",
   "metadata": {},
   "source": [
    "---\n",
    "now move forward and do words that are unique to each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3bb9be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_unique = hc_summary[~hc_summary['Word'].isin(dt_summary['Word'])]\n",
    "dt_unique = dt_summary[~dt_summary['Word'].isin(hc_summary['Word'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "25d014ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we take only more common words with freq>3\n",
    "hc_words = pd.read_csv('clinton_unique.csv')\n",
    "dt_words = pd.read_csv('trump_unique.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a8290067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_larger_cate(x):\n",
    "    if x == 'other' or x == 'time':\n",
    "        return 'other_topic'\n",
    "    elif x in demographic or x=='religion':\n",
    "        return 'demographic_issue'\n",
    "    elif x in campaign_msg or x=='media' or x=='spanish':\n",
    "        return 'campaign_message'\n",
    "    elif x in national_identity:\n",
    "        return 'national_identity'\n",
    "    elif x in economic_policy:\n",
    "        return 'economic_policy'\n",
    "    elif x in security_policy:\n",
    "        return 'security_policy'\n",
    "    elif x in social_issue:\n",
    "        return 'social_issue'\n",
    "    elif x in emotional_word:\n",
    "        return 'emotional_word'\n",
    "    else:\n",
    "        return 'opponents_reference'\n",
    "\n",
    "hc_words['topic'] = hc_words['category'].apply(add_larger_cate)\n",
    "dt_words['topic'] = dt_words['category'].apply(add_larger_cate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "e25db731",
   "metadata": {},
   "outputs": [],
   "source": [
    "myohe = OneHotEncoder()\n",
    "myoheclass = myohe.fit_transform(hc_words.category.values.reshape(-1,1)).toarray()\n",
    "hc_words = pd.concat([hc_words, pd.DataFrame(myoheclass, columns=list(myohe.categories_[0]))], axis=1)\n",
    "\n",
    "myohe2 = OneHotEncoder()\n",
    "myohetopic = myohe2.fit_transform(hc_words.topic.values.reshape(-1,1)).toarray()\n",
    "hc_words = pd.concat([hc_words, pd.DataFrame(myohetopic, columns=list(myohe2.categories_[0]))], axis = 1)\n",
    "\n",
    "myohe = OneHotEncoder()\n",
    "myoheclass = myohe.fit_transform(dt_words.category.values.reshape(-1,1)).toarray()\n",
    "dt_words = pd.concat([dt_words, pd.DataFrame(myoheclass, columns=list(myohe.categories_[0]))], axis=1)\n",
    "\n",
    "myohe2 = OneHotEncoder()\n",
    "myohetopic = myohe2.fit_transform(dt_words.topic.values.reshape(-1,1)).toarray()\n",
    "dt_words = pd.concat([dt_words, pd.DataFrame(myohetopic, columns=list(myohe2.categories_[0]))], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "c4759c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put together with the words in common, all_dt has all the words trump posted\n",
    "temp = all_common.rename(columns={\"Frequency_dt\": \"Frequency\", \"percent_dt\": \"percent\"})\n",
    "cols = dt_words.columns.to_list()\n",
    "cols.remove('religion')\n",
    "temp = temp[cols]\n",
    "all_dt = pd.concat([temp, dt_words]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9026460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = all_common.rename(columns={\"Frequency_hc\": \"Frequency\", \"percent_hc\": \"percent\"})\n",
    "cols = hc_words.columns.to_list()\n",
    "cols.remove('spanish')\n",
    "cols.remove('religion')\n",
    "temp = temp[cols]\n",
    "all_hc = pd.concat([temp, hc_words]).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8a340a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = lambda x: x.count()\n",
    "trump_cate = all_dt.groupby('category').agg({\"Frequency\":sum, \"percent\":count, \"topic\":min}).rename(columns={\"percent\":\"count\"})\n",
    "clinton_cate = all_hc.groupby('category').agg({\"Frequency\":sum, \"percent\":count, \"topic\":min}).rename(columns={\"percent\":\"count\"})\n",
    "category_summary = pd.concat([clinton_cate, trump_cate], axis=1).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6f4f74c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>clinton_freq</th>\n",
       "      <th>clinton_count</th>\n",
       "      <th>topic</th>\n",
       "      <th>trump_freq</th>\n",
       "      <th>trump_count</th>\n",
       "      <th>campaign_message</th>\n",
       "      <th>demographic_issue</th>\n",
       "      <th>economic_policy</th>\n",
       "      <th>emotional_word</th>\n",
       "      <th>national_identity</th>\n",
       "      <th>opponents_reference</th>\n",
       "      <th>other_topic</th>\n",
       "      <th>security_policy</th>\n",
       "      <th>social_issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>51</td>\n",
       "      <td>6</td>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>attack</td>\n",
       "      <td>105</td>\n",
       "      <td>16</td>\n",
       "      <td>emotional_word</td>\n",
       "      <td>534</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>econ</td>\n",
       "      <td>429</td>\n",
       "      <td>49</td>\n",
       "      <td>economic_policy</td>\n",
       "      <td>223</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>edu</td>\n",
       "      <td>305</td>\n",
       "      <td>21</td>\n",
       "      <td>social_issue</td>\n",
       "      <td>53</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>endorse</td>\n",
       "      <td>903</td>\n",
       "      <td>52</td>\n",
       "      <td>emotional_word</td>\n",
       "      <td>1064</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>environ</td>\n",
       "      <td>57</td>\n",
       "      <td>12</td>\n",
       "      <td>social_issue</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>event</td>\n",
       "      <td>1057</td>\n",
       "      <td>51</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>2385</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>foreign</td>\n",
       "      <td>208</td>\n",
       "      <td>44</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>350</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>394</td>\n",
       "      <td>29</td>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>174</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>health</td>\n",
       "      <td>255</td>\n",
       "      <td>23</td>\n",
       "      <td>social_issue</td>\n",
       "      <td>93</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>immig</td>\n",
       "      <td>144</td>\n",
       "      <td>13</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>105</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job</td>\n",
       "      <td>465</td>\n",
       "      <td>33</td>\n",
       "      <td>economic_policy</td>\n",
       "      <td>257</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>justice</td>\n",
       "      <td>372</td>\n",
       "      <td>35</td>\n",
       "      <td>social_issue</td>\n",
       "      <td>267</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lgbt</td>\n",
       "      <td>57</td>\n",
       "      <td>5</td>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>media</td>\n",
       "      <td>73</td>\n",
       "      <td>19</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>450</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>millitary</td>\n",
       "      <td>84</td>\n",
       "      <td>12</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>name</td>\n",
       "      <td>3458</td>\n",
       "      <td>108</td>\n",
       "      <td>opponents_reference</td>\n",
       "      <td>2889</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>neg</td>\n",
       "      <td>467</td>\n",
       "      <td>69</td>\n",
       "      <td>emotional_word</td>\n",
       "      <td>820</td>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>other</td>\n",
       "      <td>10309</td>\n",
       "      <td>1732</td>\n",
       "      <td>other_topic</td>\n",
       "      <td>9392</td>\n",
       "      <td>1732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patriotic</td>\n",
       "      <td>798</td>\n",
       "      <td>24</td>\n",
       "      <td>national_identity</td>\n",
       "      <td>599</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>policy</td>\n",
       "      <td>589</td>\n",
       "      <td>46</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>480</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>poverty</td>\n",
       "      <td>553</td>\n",
       "      <td>32</td>\n",
       "      <td>social_issue</td>\n",
       "      <td>156</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>promise</td>\n",
       "      <td>2015</td>\n",
       "      <td>59</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>2279</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>race</td>\n",
       "      <td>211</td>\n",
       "      <td>23</td>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>78</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>religion</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>security</td>\n",
       "      <td>388</td>\n",
       "      <td>45</td>\n",
       "      <td>security_policy</td>\n",
       "      <td>310</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>slogan</td>\n",
       "      <td>302</td>\n",
       "      <td>11</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>288</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spanish</td>\n",
       "      <td>389</td>\n",
       "      <td>39</td>\n",
       "      <td>campaign_message</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>state</td>\n",
       "      <td>189</td>\n",
       "      <td>44</td>\n",
       "      <td>national_identity</td>\n",
       "      <td>741</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>tax</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>economic_policy</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>time</td>\n",
       "      <td>206</td>\n",
       "      <td>11</td>\n",
       "      <td>other_topic</td>\n",
       "      <td>185</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>trade</td>\n",
       "      <td>160</td>\n",
       "      <td>16</td>\n",
       "      <td>economic_policy</td>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>union</td>\n",
       "      <td>697</td>\n",
       "      <td>29</td>\n",
       "      <td>national_identity</td>\n",
       "      <td>397</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     category  clinton_freq  clinton_count                topic  trump_freq  \\\n",
       "0         age            51              6    demographic_issue          14   \n",
       "1      attack           105             16       emotional_word         534   \n",
       "2        econ           429             49      economic_policy         223   \n",
       "3         edu           305             21         social_issue          53   \n",
       "4     endorse           903             52       emotional_word        1064   \n",
       "5     environ            57             12         social_issue          50   \n",
       "6       event          1057             51     campaign_message        2385   \n",
       "7     foreign           208             44      security_policy         350   \n",
       "8      gender           394             29    demographic_issue         174   \n",
       "9      health           255             23         social_issue          93   \n",
       "10      immig           144             13      security_policy         105   \n",
       "11        job           465             33      economic_policy         257   \n",
       "12    justice           372             35         social_issue         267   \n",
       "13       lgbt            57              5    demographic_issue           7   \n",
       "14      media            73             19     campaign_message         450   \n",
       "15  millitary            84             12      security_policy          80   \n",
       "16       name          3458            108  opponents_reference        2889   \n",
       "17        neg           467             69       emotional_word         820   \n",
       "18      other         10309           1732          other_topic        9392   \n",
       "19  patriotic           798             24    national_identity         599   \n",
       "20     policy           589             46     campaign_message         480   \n",
       "21    poverty           553             32         social_issue         156   \n",
       "22    promise          2015             59     campaign_message        2279   \n",
       "23       race           211             23    demographic_issue          78   \n",
       "24   religion            14              2    demographic_issue          41   \n",
       "25   security           388             45      security_policy         310   \n",
       "26     slogan           302             11     campaign_message         288   \n",
       "27    spanish           389             39     campaign_message           0   \n",
       "28      state           189             44    national_identity         741   \n",
       "29        tax            91              4      economic_policy          27   \n",
       "30       time           206             11          other_topic         185   \n",
       "31      trade           160             16      economic_policy          83   \n",
       "32      union           697             29    national_identity         397   \n",
       "\n",
       "    trump_count  campaign_message  demographic_issue  economic_policy  \\\n",
       "0             4                 0                  1                0   \n",
       "1            27                 0                  0                0   \n",
       "2            40                 0                  0                1   \n",
       "3            15                 0                  0                0   \n",
       "4            60                 0                  0                0   \n",
       "5            12                 0                  0                0   \n",
       "6            60                 1                  0                0   \n",
       "7            51                 0                  0                0   \n",
       "8            20                 0                  1                0   \n",
       "9            23                 0                  0                0   \n",
       "10           11                 0                  0                0   \n",
       "11           26                 0                  0                1   \n",
       "12           35                 0                  0                0   \n",
       "13            4                 0                  1                0   \n",
       "14           33                 1                  0                0   \n",
       "15           12                 0                  0                0   \n",
       "16          130                 0                  0                0   \n",
       "17           69                 0                  0                0   \n",
       "18         1732                 0                  0                0   \n",
       "19           23                 0                  0                0   \n",
       "20           43                 1                  0                0   \n",
       "21           26                 0                  0                0   \n",
       "22           50                 1                  0                0   \n",
       "23           17                 0                  1                0   \n",
       "24            7                 0                  1                0   \n",
       "25           48                 0                  0                0   \n",
       "26           11                 1                  0                0   \n",
       "27            0                 1                  0                0   \n",
       "28           65                 0                  0                0   \n",
       "29            4                 0                  0                1   \n",
       "30           11                 0                  0                0   \n",
       "31           15                 0                  0                1   \n",
       "32           23                 0                  0                0   \n",
       "\n",
       "    emotional_word  national_identity  opponents_reference  other_topic  \\\n",
       "0                0                  0                    0            0   \n",
       "1                1                  0                    0            0   \n",
       "2                0                  0                    0            0   \n",
       "3                0                  0                    0            0   \n",
       "4                1                  0                    0            0   \n",
       "5                0                  0                    0            0   \n",
       "6                0                  0                    0            0   \n",
       "7                0                  0                    0            0   \n",
       "8                0                  0                    0            0   \n",
       "9                0                  0                    0            0   \n",
       "10               0                  0                    0            0   \n",
       "11               0                  0                    0            0   \n",
       "12               0                  0                    0            0   \n",
       "13               0                  0                    0            0   \n",
       "14               0                  0                    0            0   \n",
       "15               0                  0                    0            0   \n",
       "16               0                  0                    1            0   \n",
       "17               1                  0                    0            0   \n",
       "18               0                  0                    0            1   \n",
       "19               0                  1                    0            0   \n",
       "20               0                  0                    0            0   \n",
       "21               0                  0                    0            0   \n",
       "22               0                  0                    0            0   \n",
       "23               0                  0                    0            0   \n",
       "24               0                  0                    0            0   \n",
       "25               0                  0                    0            0   \n",
       "26               0                  0                    0            0   \n",
       "27               0                  0                    0            0   \n",
       "28               0                  1                    0            0   \n",
       "29               0                  0                    0            0   \n",
       "30               0                  0                    0            1   \n",
       "31               0                  0                    0            0   \n",
       "32               0                  1                    0            0   \n",
       "\n",
       "    security_policy  social_issue  \n",
       "0                 0             0  \n",
       "1                 0             0  \n",
       "2                 0             0  \n",
       "3                 0             1  \n",
       "4                 0             0  \n",
       "5                 0             1  \n",
       "6                 0             0  \n",
       "7                 1             0  \n",
       "8                 0             0  \n",
       "9                 0             1  \n",
       "10                1             0  \n",
       "11                0             0  \n",
       "12                0             1  \n",
       "13                0             0  \n",
       "14                0             0  \n",
       "15                1             0  \n",
       "16                0             0  \n",
       "17                0             0  \n",
       "18                0             0  \n",
       "19                0             0  \n",
       "20                0             0  \n",
       "21                0             1  \n",
       "22                0             0  \n",
       "23                0             0  \n",
       "24                0             0  \n",
       "25                1             0  \n",
       "26                0             0  \n",
       "27                0             0  \n",
       "28                0             0  \n",
       "29                0             0  \n",
       "30                0             0  \n",
       "31                0             0  \n",
       "32                0             0  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_summary.columns = ['clinton_freq', 'clinton_count', 'topic', 'trump_freq', 'trump_count', 'topic2']\n",
    "category_summary = category_summary[category_summary.columns[:-1]]\n",
    "category_summary['trump_freq'] = category_summary['trump_freq'].astype(int)\n",
    "category_summary['trump_count'] = category_summary['trump_count'].astype(int)\n",
    "\n",
    "myohe = OneHotEncoder()\n",
    "myoheclass = myohe.fit_transform(category_summary.topic.values.reshape(-1,1)).toarray().astype(int)\n",
    "cate_summary = pd.concat([category_summary.reset_index(), pd.DataFrame(myoheclass, columns=list(myohe.categories_[0]))], axis=1)\n",
    "cate_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "853325dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cate_summary.to_csv(\"category_sum_all.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a6ea3109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>clinton_freq</th>\n",
       "      <th>clinton_count</th>\n",
       "      <th>trump_freq</th>\n",
       "      <th>trump_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>campaign_message</td>\n",
       "      <td>4362</td>\n",
       "      <td>208</td>\n",
       "      <td>5552</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>demographic_issue</td>\n",
       "      <td>727</td>\n",
       "      <td>65</td>\n",
       "      <td>314</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>economic_policy</td>\n",
       "      <td>1145</td>\n",
       "      <td>102</td>\n",
       "      <td>590</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emotional_word</td>\n",
       "      <td>1475</td>\n",
       "      <td>137</td>\n",
       "      <td>2418</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>national_identity</td>\n",
       "      <td>1684</td>\n",
       "      <td>97</td>\n",
       "      <td>1737</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>opponents_reference</td>\n",
       "      <td>3458</td>\n",
       "      <td>108</td>\n",
       "      <td>2889</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>other_topic</td>\n",
       "      <td>10515</td>\n",
       "      <td>1743</td>\n",
       "      <td>9577</td>\n",
       "      <td>1743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>security_policy</td>\n",
       "      <td>824</td>\n",
       "      <td>114</td>\n",
       "      <td>845</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>social_issue</td>\n",
       "      <td>1605</td>\n",
       "      <td>140</td>\n",
       "      <td>949</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 topic  clinton_freq  clinton_count  trump_freq  trump_count\n",
       "0     campaign_message          4362            208        5552          180\n",
       "1    demographic_issue           727             65         314           52\n",
       "2      economic_policy          1145            102         590           85\n",
       "3       emotional_word          1475            137        2418          156\n",
       "4    national_identity          1684             97        1737          111\n",
       "5  opponents_reference          3458            108        2889          130\n",
       "6          other_topic         10515           1743        9577         1743\n",
       "7      security_policy           824            114         845          122\n",
       "8         social_issue          1605            140         949          128"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = lambda x: x.count()\n",
    "trump_topic = all_dt.groupby('topic').agg({\"Frequency\":sum, \"percent\":count}).rename(columns={\"percent\":\"count\"})\n",
    "clinton_topic = all_hc.groupby('topic').agg({\"Frequency\":sum, \"percent\":count}).rename(columns={\"percent\":\"count\"})\n",
    "topic_summary = pd.concat([clinton_topic, trump_topic], axis=1)\n",
    "topic_summary.columns = ['clinton_freq', 'clinton_count', 'trump_freq', 'trump_count']\n",
    "topic_summary = topic_summary.reset_index()\n",
    "topic_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "89e135a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_summary.to_csv('topic_sum_all.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7eba2299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9.702417854928704% of Hillary tweets is quoting of her own words, 0.06215040397762585% of Trump tweets is quoting of his words'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quote of their own\n",
    "hc_quote = hc[hc[\"text\"].str.contains(\"—hillary\", case=False, na=False)].shape[0]\n",
    "dt_quote = dt[dt[\"text\"].str.contains(\"-trump\", case=False, na=False)].shape[0]\n",
    "f'{hc_quote / hc.shape[0] * 100}% of Hillary tweets is quoting of her own words, {dt_quote / dt.shape[0]* 100}% of Trump tweets is quoting of his words'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdafcda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24798512089274644% of Hillary tweets is quoting of Trump, 0.031075201988812924% of Trump tweets is quoting of Hillary'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quote of each other\n",
    "hc_qo = hc[hc[\"text\"].str.contains(\"—Trump\", case=False, na=False)].shape[0]\n",
    "dt_qo = dt[dt[\"text\"].str.contains(\"-Clinton\", case=False, na=False)].shape[0]\n",
    "f'{hc_qo / hc.shape[0] * 100}% of Hillary tweets is quoting of Trump, {dt_qo / dt.shape[0]* 100}% of Trump tweets is quoting of Hillary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11eae27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8679479231246126% of Hillary tweets mentioned Stronger Together, 3.6047234307022995% of Trump tweets meantioned Great Again'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##campaign slogan\n",
    "hc_slogan = hc[hc[\"text\"].str.contains(\"Stronger Together\", case=False, na=False)].shape[0]\n",
    "dt_slogan = dt[dt[\"text\"].str.lower().str.contains(\"great again\",case=False, na=False)].shape[0]\n",
    "f'{hc_slogan/ hc.shape[0] * 100}% of Hillary tweets mentioned Stronger Together, {dt_slogan / dt.shape[0]* 100}% of Trump tweets meantioned Great Again'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "608d439d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About immigration, Trump often use ['wall', 'illegal', 'immigration', 'mexico', 'borders', 'border', 'refugees', 'illegals', 'wallace', 'illegally', 'refugee', 'walls', 'wallsis', 'wallet', 'interviewall', 'borderless', 'immigrationif', 'prowall', 'deportation'] and it consists of 546.9235550031075 of his tweets,Hillary often use ['wall', 'immigration', 'walls', 'deport', 'mexico', 'deportation', 'deported', 'illegal', 'deportar', 'stonewall', 'deportación', 'refugees', 'immigrate', 'wallet', 'wallinstead', 'walldid', 'deporting', 'refugee', 'border', 'deportations'] and it consists of 325.4804711717297 of her tweets, one of it is about Lets imagine a tomorrow in which no child grows up under the shadows of discrimination or deportation\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trump immigration promise\n",
    "immig_words = [\"border\", \"deport\", \"mexico\", \"wall\", \"refugee\",\"illegal\", 'immigrat']\n",
    "dt_immig = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "dt_immig_words = [i for i in dt_immig[\"Word\"]]\n",
    "dt_immig_p = dt_immig.sum()\n",
    "hc_immig = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in immig_words))]\n",
    "hc_immig_words = [i for i in hc_immig[\"Word\"]]\n",
    "hc_immig_p = hc_immig.sum()\n",
    "f'About immigration, Trump often use {dt_immig_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_immig_words} and it consists of {hc_immig_p.loc[\"percent\"]*100} of her tweets, one of it is about Lets imagine a tomorrow in which no child grows up under the shadows of discrimination or deportation'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "255c7342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'About immigration, Trump often use [\\'tax\\', \\'taxes\\', \\'overtaxes\\', \\'overtaxed\\', \\'taxpayers\\'] and it consists of 463.02050963331254 of his tweets,Hillary often use [\\'tax\\', \\'taxes\\', \\'taxpayers\\', \\'taxpayer\\', \\'taxesand\\'] and it consists of 285.18288902665836 of her tweets, one of it is about Last night, Donald Trump said not paying taxes was \"smart.\" You know what I call it? Unpatriotic.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trump tax cut\n",
    "tax_words = [\"tax\"]\n",
    "dt_tax = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "dt_tax_words = [i for i in dt_tax[\"Word\"]]\n",
    "dt_tax_p = dt_tax.sum()\n",
    "hc_tax = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in tax_words))]\n",
    "hc_tax_words = [i for i in hc_tax[\"Word\"]]\n",
    "hc_tax_p = hc_tax.sum()\n",
    "f'About taxation, Trump often use {dt_tax_words} and it consists of {dt_immig_p.loc[\"percent\"]*100} of his tweets,Hillary often use {hc_tax_words} and it consists of {hc_tax_p.loc[\"percent\"]*100} of her tweets, one of it is about Last night, Donald Trump said not paying taxes was \"smart.\" You know what I call it? Unpatriotic.'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c2ff001b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"About health plan, Trump often use ['care', 'obamacare', 'careful', 'healthcare', 'cares', 'career', 'scared', 'insurance', 'pledgecareful', 'ocare', 'childcare', 'medical', 'careers', 'careless', 'scare'] and it consists of 546.9235550031075% of his tweets,Hillary often use ['care', 'affordable', 'career', 'insurance', 'cares', 'medical', 'scared', 'careerfocused', 'scares', 'careerand', 'childcare', 'medicare', 'heath', 'scare'] and it consists of 322.38065716057037 of her tweets.\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hillary health promise(need to be modified)\n",
    "health_words = [\"heath\",\"affordable\",\"care\", 'insurance','medical']\n",
    "dt_health = dt_summary[dt_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "dt_health_words = [i for i in dt_health[\"Word\"]]\n",
    "dt_health_p = dt_health.sum()\n",
    "hc_health = hc_summary[hc_summary['Word'].apply(lambda tweet: any(word in tweet.lower() for word in health_words))]\n",
    "hc_health_words = [i for i in hc_health[\"Word\"]]\n",
    "hc_health_p = hc_health.sum()\n",
    "f'About health plan, Trump often use {dt_health_words} and it consists of {dt_immig_p.loc[\"percent\"]*100}% of his tweets,Hillary often use {hc_health_words} and it consists of {hc_health_p.loc[\"percent\"]*100} of her tweets.'\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
